---
title: "Chen_to_Kwon_Classifier"
author: "Angus Campbell"
date: "2022-10-09"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Reference for pdf documents: https://github.com/svmiller/svm-r-markdown-templates/blob/master/article-example/svm-rmarkdown-article-example.Rmd

https://github.com/svmiller/svm-r-markdown-templates/blob/master/article-example/svm-rmarkdown-article-example.pdf


```{r}
setwd("~/PavLabEngrams/EngramCellClassifier/RemoteMemory")

# libraries used
library(randomForest)
library(rfUtilities)
library(Seurat)
library(stringr)
library(sampler)
library(caTools)
library(pROC)
library(ggplot2)
library(stats)
library(Dict)
library(pheatmap)
library(caret)
library(data.table)
library(dplyr)
library(aod) #for logistic regression
#library(lme4) apparently lme4 cannot be loaded with seurat
library(tidyverse)
```


# Integrating Chen and Kwon
 
Kwon should have "adult control (15911 nuclei) and CUS (15349 nuclei)"

I tried matching the cell clusters just based on markers but to no avail so I feel it is best to do it across clusters.  There could be a variety of reasons for this issue, they both used the Log normalized methods where I was using sct transform, also the chronic stress condition (CUS) may have been an issue.  As Chen has cases of just a few cells coming from one mouse I have opted instead to 

Orginally I integrated over mouse replicates in
Kwon as they noted severe batch effects in the text.  I will

This articel could be useful for getting comperable cell classes (also has data we could use, huan and mouse) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5623139/





The clustering will be done in seurat following standard integration, I will od it over conditions so homecage, CUS and then the Fear groups etc.
##Create and merge counts data
```{r}
# seems like this fiel cannot open the connection
# we will have to make plots in a seperate R script
# just add relevant figures here and reference the script

#kwon 
kwon2021_counts <- read.table("~/test_datasets/Kwon2021_GSE145970/kwon2021_mpfc_neurons_counts.csv.gz",
                              header = TRUE, sep =",")
rownames(kwon2021_counts) <- kwon2021_counts$GENE

chenkwon.combined.meta <- read.csv("~/test_datasets/Kwon2021_GSE145970/kwon_mpfc_neurons_meta.csv",
                          header = TRUE)

# there was a discrepancy between the names in kwon meta dat cell id and the counts
# this commented out code is here to fix it
# fun <- function(x){
#    out <- str_c(
#      str_sub(x, start = 1L, end = 12L), 
#      "_", 
#      str_sub(x, start = 13L)
#      )
#    return(out)}
# 
# kwon2021_meta$CellID <- lapply(kwon2021_meta$CellID, FUN = fun)

# filter kwon2021_coutns to match cells in the metadata
kwon2021_meta <- chenkwon.combined.meta[chenkwon.combined.meta$CellID %in% colnames(kwon2021_counts), ]

kwon2021_counts <- kwon2021_counts[,colnames(kwon2021_counts) %in% kwon2021_meta$CellID ]

# these clusters in kwon data from res0.046 are cortical cells
# cortex.clusters <- c(0, 1, 2, 3, 4, 6, 9, 10, 12, 13, 14, 16, 20, 25)

# we're removing chen cells from this step
```


 
```{r}
#Chen
chen2020_counts <- read.csv('~/PavLabEngrams/EngramCellClassifier/Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rownames(chen2020_counts) <- chen2020_counts$X
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta <- read.csv( '~/PavLabEngrams/EngramCellClassifier/Chen2020_GSE152632/SraRunTable.txt', header = TRUE)

#add engram label
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))

#create the condition label
condition_label <- chen2020_meta$source_name %>%
  sapply( function(y) if (grepl("Homecage", y, fixed=TRUE)) "Homecage")

condition_label <- chen2020_meta$source_name
condition_label[str_detect(condition_label, "Homecage")] = "Homecage"
condition_label[str_detect(condition_label, "Context-Only")] = "Context-Only"
condition_label[str_detect(condition_label, "Fear-Only")] = "Fear-Only"
condition_label[str_detect(condition_label, "Fear-Recall")] = "Fear-Recall"
chen2020_meta$condition_label <- condition_label

#adding cell bacrcodes from coutn data to rows of metadata for seurat
rownames(chen2020_meta) <- colnames(chen2020_counts)


chen2020_meta <- cbind(chen2020_meta, read.csv("~/PavLabEngrams/EngramCellClassifier/Chen2020_GSE152632/Chen2020_ClusterMarkers.csv") )


```

Now we can actually cluster.

```{r}
kwon2021_counts$GENE <- rownames(kwon2021_counts) 
chen2020_counts$GENE <- rownames(chen2020_counts)

chenkwon.combined.counts <- left_join(chen2020_counts, kwon2021_counts, by = "GENE") %>%
  column_to_rownames( var = "GENE") 

chenkwon.combined.counts <- full_join(chen2020_counts, kwon2021_counts, by = "GENE") %>%
  column_to_rownames( var = "GENE") 

chenkwon.combined.counts[is.na(chenkwon.combined.counts)] <- 0

```


```{r}
# this has already been generated we can probably remove it


chenkwon.combined.meta <- data.frame(condition = c(chen2020_meta$condition_label, kwon2021_meta$condition))
# old code
#chenkwon.combined.meta$og_cluster <-  c(chen2020_meta$ChenLayerMarkers, kwon2021_meta$cluster_markers_res0.46)
chenkwon.combined.meta$og_cluster <-  c(chen2020_meta$ChenLayerMarkers, kwon2021_meta$mpfc_integrated_marker)

# we're gonna consider the controls and home cage separate
chenkwon.combined.meta$condition <- as.factor(chenkwon.combined.meta$condition)

chenkwon.combined.meta$label_status <- as.factor(c(as.character(chen2020_meta$engram_label), rep("discovery_data", dim(kwon2021_counts)[2]-1))) # -1 because of the GENE column


chenkwon.combined.meta$CellID <- colnames(chenkwon.combined.counts)
rownames(chenkwon.combined.meta) <- colnames(chenkwon.combined.counts)

rownames(chenkwon.combined.meta) <- colnames(chenkwon.combined.counts)
```









## Classifiers

 

```{r include=FALSE}
# FUNCTIONS


pseudocount_log2p1_transform <- function(x, scale_factor = 10^6, UMI.provided = NULL){
  # Almost as Seurat::NormalizeData but we use log2 rather than natural log
  # from here https://satijalab.org/seurat/reference/normalizedata
  if(is.null(UMI.provided)){
    counts <- sum(x)}else{
      counts <- UMI.provided
    }
  x <- (x)/counts # Feature counts for each cell are divided by the total counts for that cell...
  x <- x*scale_factor # and multiplied by the scale.factor. 
  # the we log2 plus 1 rather than natural log plus 1 seurat uses
  return(log2(x+1))
}

pavlab.normalize <- function(df, UMI = NULL, median.scale=FALSE, scaleby = 10000){
  df.cols <- colnames(df)
  df.rows <- rownames(df)
  if(median.scale){ scaleby = median(UMI)}
  if( is.null(UMI)){
    df <- data.frame(apply(df,  MARGIN = 2, pseudocount_log2p1_transform))
  }else{
    #
    df[] <- Map(pseudocount_log2p1_transform, df, scale_factor = scaleby, UMI.provided = UMI)
    
  }
  colnames(df) <- df.cols
  rownames(df)<- df.rows
  return(df)
}


#normalization functions, log.norm calls logplusone
seurat_log1p_transform <- function(x, scale_factor = 10000, UMI.provided = NULL){
  # as per the LogNormalize option in Seurat::NormalizeData
  # from this URL: https://satijalab.org/seurat/reference/normalizedata
  if(is.null(UMI.provided)){
    counts <- sum(x)}else{
      counts <- UMI.provided
    }
  x <- (x)/counts # Feature counts for each cell are divided by the total counts for that cell... 
  x <- x*scale_factor # and multiplied by the scale.factor. 
  # This is then natural-log transformed using log1p.
  return(log(x+1))
}

seurat.normalize <- function(df, UMI = NULL, median.scale=FALSE, scaleby = 10000){
  df.cols <- colnames(df)
  df.rows <- rownames(df)
  if(median.scale){ scaleby = median(UMI)}
  if( is.null(UMI)){
    df <- data.frame(apply(df,  MARGIN = 2, seurat_log1p_transform))
  }else{
    #
    df[] <- Map(seurat_log1p_transform, df, UMI.provided = UMI, scale_factor = scaleby)
  }
  colnames(df) <- df.cols
  rownames(df)<- df.rows
  return(df)
}


#normalization functions, log.norm calls logplusone
# mean center scale then log(x+1) for normalizing
logplusone <- function(x){
  return( log(x+1) )
}

log.norm <- function(df.in){
  #performs the lognorm transform and scales the data, removes NA's first
  if( sum(is.na(df.in)) ){
    df.in[is.na(df.in)] <- 0
  }
  df.out <- apply(df.in,
                  MARGIN = 1,
                  FUN = logplusone
  )
  df.out <- scale( t(df.out) ) #we need it transposed so that the scaling is done per gene not cell
  df.out <- data.frame( t(df.out) )
  colnames(df.out) <- rownames(df.in)
  return(df.out)
}

scale.and.rotate<-function(df.in){
  incols <- colnames(df.in)
  inrows <- rownames(df.in)
  df.in <- t(df.in)
  df.in <- scale(df.in)
  df.in <- data.frame(df.in)
  rownames(df.in) <- incols
  colnames(df.in) <- inrows
  return(df.in)
}

celltype.lognorm <-function(countsdata, celltype.labels){
  #log normalizes within cell types in counts data
  #celltype labels and colnames of countsdata must have same order
  
  #retunrs a transposed and normalize dataframe 
  
  print("Normalizing cell type...")
  
  celltypes <- unique(celltype.labels)
  df.out <- data.frame(gene = rownames(countsdata))
  #df.out <- t(df.out)
  #colnames(df.out) <- rownames(countsdata)
  
  cell_names <- colnames(countsdata) # keep this for reorganizing later
  df.out.rownames <- c()
  for(type in celltypes){
    print(type[1])
    normalized.within.type <- log.norm(countsdata[,celltype.labels==type])
    normalized.within.type <- t(normalized.within.type ) # lognomr flips its data
    normalized.within.type <- data.frame(normalized.within.type)
    normalized.within.type <- rownames_to_column(normalized.within.type, var ="gene")
    df.out <- left_join( df.out, normalized.within.type, by = 'gene' )
  }
  
  df.out <- df.out[,2:dim(df.out)[2]] # drops gene column
  df.out <- df.out[cell_names] # to keep original order
  df.out <- t(df.out)
  return( data.frame(df.out) ) 
}

#modified version of randomForest::combine() which can handle different sized forests
# without this it throws and error when combining the votes
my_combine <- function (...) 
{
  pad0 <- function(x, len) c(x, rep(0, len - length(x)))
  padm0 <- function(x, len) rbind(x, matrix(0, nrow = len - 
                                              nrow(x), ncol = ncol(x)))
  rflist <- list(...)
  areForest <- sapply(rflist, function(x) inherits(x, "randomForest"))
  if (any(!areForest)) 
    stop("Argument must be a list of randomForest objects")
  rf <- rflist[[1]]
  classRF <- rf$type == "classification"
  trees <- sapply(rflist, function(x) x$ntree)
  ntree <- sum(trees)
  rf$ntree <- ntree
  nforest <- length(rflist)
  haveTest <- !any(sapply(rflist, function(x) is.null(x$test)))
  vlist <- lapply(rflist, function(x) rownames(importance(x)))
  numvars <- sapply(vlist, length)
  if (!all(numvars[1] == numvars[-1])) 
    stop("Unequal number of predictor variables in the randomForest objects.")
  for (i in seq_along(vlist)) {
    if (!all(vlist[[i]] == vlist[[1]])) 
      stop("Predictor variables are different in the randomForest objects.")
  }
  haveForest <- sapply(rflist, function(x) !is.null(x$forest))
  if (all(haveForest)) {
    nrnodes <- max(sapply(rflist, function(x) x$forest$nrnodes))
    rf$forest$nrnodes <- nrnodes
    rf$forest$ndbigtree <- unlist(sapply(rflist, function(x) x$forest$ndbigtree))
    rf$forest$nodestatus <- do.call("cbind", lapply(rflist, 
                                                    function(x) padm0(x$forest$nodestatus, nrnodes)))
    rf$forest$bestvar <- do.call("cbind", lapply(rflist, 
                                                 function(x) padm0(x$forest$bestvar, nrnodes)))
    rf$forest$xbestsplit <- do.call("cbind", lapply(rflist, 
                                                    function(x) padm0(x$forest$xbestsplit, nrnodes)))
    rf$forest$nodepred <- do.call("cbind", lapply(rflist, 
                                                  function(x) padm0(x$forest$nodepred, nrnodes)))
    tree.dim <- dim(rf$forest$treemap)
    if (classRF) {
      rf$forest$treemap <- array(unlist(lapply(rflist, 
                                               function(x) apply(x$forest$treemap, 2:3, pad0, 
                                                                 nrnodes))), c(nrnodes, 2, ntree))
    }
    else {
      rf$forest$leftDaughter <- do.call("cbind", lapply(rflist, 
                                                        function(x) padm0(x$forest$leftDaughter, nrnodes)))
      rf$forest$rightDaughter <- do.call("cbind", lapply(rflist, 
                                                         function(x) padm0(x$forest$rightDaughter, nrnodes)))
    }
    rf$forest$ntree <- ntree
    if (classRF) 
      rf$forest$cutoff <- rflist[[1]]$forest$cutoff
  }
  else {
    rf$forest <- NULL
  }
  #
  #Tons of stuff removed here...
  #
  if (classRF) {
    rf$confusion <- NULL
    rf$err.rate <- NULL
    if (haveTest) {
      rf$test$confusion <- NULL
      rf$err.rate <- NULL
    }
  }
  else {
    rf$mse <- rf$rsq <- NULL
    if (haveTest) 
      rf$test$mse <- rf$test$rsq <- NULL
  }
  rf
}



resample.randomForest <-function( df.in,
                                  under_represented_class,
                                  over_represented_class,
                                  proportion,
                                  batches, 
                                  trees){
  #NOTE: df.in should have a column called engram cell with the class labels i.e. postive or negative

  #this function resamples from our samples and retrains new models then combines them
  # this is too prevent over fitting on cells
  trees.per.batch <- as.integer(trees/batches)
  n.cells <- trunc( sum(df.in$Engramcell==under_represented_class)*proportion)
  batches <- c(1:batches)
  
  for( batch in batches){
    resample.set <- rbind(sample(which(df.in$Engramcell==under_represented_class), size = n.cells),
                          sample(which(df.in$Engramcell==over_represented_class), size = n.cells)
                          )
    resample.set <- df.in[resample.set,]
    
    # creates rf.model
    if(batch==1){
      rf.model <- randomForest(x = resample.set[,1:(length(resample.set)-1)],
                               y = resample.set$Engramcell,
                               ntree = trees.per.batch)
      
                        
    }
    #trains new models in rf.fit and combines tham with rf.model
    if(batch>1){
      rf.fit = randomForest(x = resample.set[,1:(length(resample.set)-1)],
                            y = resample.set$Engramcell,
                            ntree = trees.per.batch)
      
      rf.model <- randomForest::my_combine(rf.fit, rf.model)
    }
  }#end of for loop over batches
  
  return(rf.model)
}



make.predictions.df <- function(classifier.object, 
                                test_df,
                                meta.data.label.column,
                                label = c("Inactive","Active")
                                ){
  #generate predictions for making classifier summary
  predictions <- as.data.frame(predict(classifier.object, test_df[,1:(length(test_df))], type = "prob"))
  predictions$predict <- names(predictions)[1:2][apply(predictions[,1:2], 1, which.max)] #1:2 for the number of classes
  predictions$observed <- meta.data.label.column #this should be changed if you want to make this functions more modular
  colnames(predictions)[1:2] <- c("label_neg","label_pos")
  predictions$engramobserved <- ifelse(predictions$observed==label[1], 1, 0)
  predictions$inactiveobserved <- ifelse(predictions$observed==label[2], 1, 0)
  return(predictions)
}


# assess a single run of resampled.randomforest
assessment <- function(predictions.df, 
                       label = c("Active","Inactive") 
                       ){
  # returns a vector of assessments to be used to make dataframe summarizing classifiers performance
  # can be used to make df of all classifiers trained in a single run
  TP <- sum((predictions.df$predict == label[1])&(predictions.df$observed == label[1]))
  TN <- sum((predictions.df$predict == label[2])&(predictions.df$observed == label[2]))
  FN <- sum((predictions.df$predict == label[2])&(predictions.df$observed == label[1]))
  FP <- sum((predictions.df$predict == label[1])&(predictions.df$observed == label[2]))
  
  #precision and recall as well as sumamry stats F1
  precision <- TP/(TP+FP)
  recall <- TP/(TP+FN)
  F1.score = 2 * (precision * recall) / (precision + recall)
  FPR <- FP/(TN+FP)
  FNR <- FN/(TP+FN)
  
  #getting auc
  roc.engramcell <- roc(predictions.df$engramobserved, as.numeric(predictions.df$label_pos) )
  AUC <- auc(roc.engramcell)
  
  return( c(F1.score, AUC, precision, recall, FPR, FNR,
            TP, FN, TN, FP) )
}




resampled.randomForest.crossvalidated <-function(data,
                                                 under.represented.class,
                                                 over.represented.class,
                                                 folds,
                                                 trees.total,
                                                 proportion.each.batch=0.8,
                                                 batches.per.fold=20){
  # takes a data frame with a label column assumed to be named Engramcell, data$Engramcell
  # returns a model that has been k-fold cross validated, with an attribute called Assessment
  # assessment has the performance metrics of all the folds and a column of means and SD's for each
  # metric
  #NOTE: ROC curve needs to be implemented
  
  roc.list <- c()
  index.list <- c() # list of idx.thisfold, indeces of test and training
  folds.obj <- createFolds(data$Engramcell, k = folds)
  loops <- c(1:folds)
  for( i in loops ){
    
    idx.thisfold <- c()
    #create indices
    test.idx <- rownames(data)[ folds.obj[[i]] ]
    idx.thisfold$test <- test.idx
    # needs to be a list so it can act as an index
    train.idx <- rownames(data)[!(rownames(data) %in% test.idx)]
    idx.thisfold$train <- train.idx
    index.list <- c(index.list,idx.thisfold)
    #split data for this fold
    training_set <- data[train.idx,]
    testing_set <- data[test.idx,]
    #roc.list <- c() # roc lsit for ggroc for per fold roc curves
    # divvies up number of trees
    trees.in.the.fold = as.integer(trees.total/folds)
    if ( ( trees.total%%(batches.per.fold*folds) )>0  ){ 
      stop("Number of trees does not devide evenly by batches and folds.")
    }
    # we still need to settle on stuff to 
    rf.this_fold <- resample.randomForest(df.in = training_set,
                                          under_represented_class = under.represented.class,
                                          over_represented_class = over.represented.class,
                                          proportion= proportion.each.batch,
                                          batches = batches.per.fold, 
                                          trees = trees.in.the.fold)
    
    if(i == 1){
      rf.out <- rf.this_fold
      pred <- make.predictions.df(rf.this_fold, testing_set[1:(length(testing_set)-1)], testing_set$Engramcell)
      assess <- assessment( pred ) 
      fold.performance <- data.frame(assess )
      rownames(fold.performance) <- c("F1 Score", "AUC", "Precision", "Recall",
                                      "FPR", "FNR", "True Positives", "False Negatives", 
                                      "True Negatives", "False Positives")
      # making roc list
      pred.fold.votes <- predict(rf.out,
                                 testing_set[1:(length(testing_set)-1)], 
                                 type = 'prob')
      head(pred.fold.votes)
      roc.list <- list( roc(testing_set$Engramcell, pred.fold.votes[,2]) )
    }else{
      print(dim(testing_set))
      # making roc list
      pred.fold.votes <- predict(rf.this_fold,
                           testing_set[1:(length(testing_set)-1)], 
                           type = 'prob')
      head(pred.fold.votes)
      roc.list <- append(roc.list, list( roc(testing_set$Engramcell, pred.fold.votes[,2]) ) )
      #rf.out <- randomForest::combine(rf.out, rf.this_fold) #old code can't handle the 
      rf.out <- my_combine(rf.out, rf.this_fold)
      # we need votes for all cells to calculate
      pred <- make.predictions.df(rf.this_fold, testing_set[1:(length(testing_set)-1)], testing_set$Engramcell)
      assess <- assessment( pred ) 
      fold.performance[,ncol(fold.performance) + 1] <- assess
      
    }
    
  }# end of for loop
  colnames(fold.performance) <- names(folds.obj)
  fold.performance$Mean <- apply(fold.performance,MARGIN=1,  FUN = mean)
  fold.performance$SigDiff <- apply(fold.performance,MARGIN=1,  FUN = sd)
  rf.out$Assessment <- fold.performance
  
  #votes needs to be updated to make roc curve
  rf.out$votes <- predict(object = rf.out, newdata = data, type = 'vote', norm.votes = FALSE)
  rf.out$roc_perfold <- roc.list
  rf.out$caretfolds.obj <- folds.obj
  rf.out$testntrain.indexs <- index.list
  return(rf.out)
}




resample.regularizedRF <- function( df.in,
                                    under_represented_class,
                                    over_represented_class,
                                    proportion,
                                    batches, 
                                    trees){
  #NOTE: df.in should have a column called engram cell with the class labels i.e. postive or negative
  
  #this function resamples from our samples and retrains new models then combines them
  # this is too prevent over fitting on cells
  trees.per.batch <- as.integer(trees/batches)
  n.cells <- trunc( sum(df.in$Engramcell==under_represented_class)*proportion)
  batches <- c(1:batches)
  for( batch in batches){
    resample.set <- rbind(sample(which(df.in$Engramcell==under_represented_class), size = n.cells),
                          sample(which(df.in$Engramcell==over_represented_class), size = n.cells)
    )
    resample.set <- df.in[resample.set,]
    
    # creates rf.model
    if(batch==1){
      rf.model <- RRF(x = resample.set[,1:(length(resample.set)-1)],
                      y = resample.set$Engramcell,
                      ntree = trees.per.batch)
    }
    #trains new models in rf.fit and combines tham with rf.model
    if(batch>1){
      rf.fit = RRF(x = resample.set[,1:(length(resample.set)-1)],
                   y = resample.set$Engramcell,
                   ntree = trees.per.batch)
      rf.model <- RRF::combine(rf.fit, rf.model)
    }
  }#end of for loop over batches
  
  return(rf.model)
}

#
resampled.regularizedRF.crossvalidated <-function(data,
                                                  under.represented.class,
                                                  over.represented.class,
                                                  folds,
                                                  trees.total,
                                                  proportion.each.batch=0.8,
                                                  batches.per.fold=20){
  # takes a data frame with a label column assumed to be named Engramcell, data$Engramcell
  # returns a model that has been k-fold cross validated, with an attribute called Assessment
  # assessment has the performance metrics of all the folds and a column of means and SD's for each
  # metric
  #NOTE: ROC curve needs to be implemented
  
  folds.obj <- createFolds(data$Engramcell, k = folds)
  loops <- c(1:folds)
  for( i in loops ){
    #create indices
    test.idx <- folds.obj[[i]]
    # needs to be a list so it can act as an index
    train.idx <- which(!(rownames(data) %in% test.idx) )
    
    #split data for this fold
    training_set <- data[train.idx,]
    testing_set <- data[test.idx,]
    
    # divvies up number of trees
    trees.in.the.fold = as.integer(trees.total/folds)
    if ( ( trees.total%%(batches.per.fold*folds) )>0  ){ 
      stop("Number of trees does not devide evenly by batches and folds.")
    }
    # we still need to settle on stuff to 
    rf.this_fold <- resample.regularizedRF(df.in = training_set,
                                           under_represented_class = under.represented.class,
                                           over_represented_class = over.represented.class,
                                           proportion= proportion.each.batch,
                                           batches = batches.per.fold, 
                                           trees = trees.in.the.fold)
    
    if(i == 1){
      rf.out <- rf.this_fold
      pred <- make.predictions.df(rf.this_fold, testing_set[1:(length(testing_set)-1)], testing_set$Engramcell)
      assess <- assessment( pred ) 
      fold.performance <- data.frame(assess )
      rownames(fold.performance) <- c("F1 Score", "AUC", "Precision", "Recall",
                                      "FPR", "FNR", "True Positives", "False Negatives", 
                                      "True Negatives", "False Positives")
    }else{
      rf.out <- RRF::combine(rf.out, rf.this_fold)
      # we need votes for all cells to calculate
      pred <- make.predictions.df(rf.this_fold, testing_set[1:(length(testing_set)-1)], testing_set$Engramcell)
      assess <- assessment( pred ) 
      fold.performance[,ncol(fold.performance) + 1] <- assess
    }
    
  }# end of for loop
  colnames(fold.performance) <- names(folds.obj)
  fold.performance$Mean <- apply(fold.performance,MARGIN=1,  FUN = mean)
  fold.performance$SigDiff <- apply(fold.performance,MARGIN=1,  FUN = sd)
  rf.out$Assessment <- fold.performance
  
  #votes needs to be updated to make roc curve
  rf.out$votes <- predict(object = rf.out, newdata = data, type = 'vote', norm.votes = FALSE)
  return(rf.out)
}



gene.shuffle <-function(dat){
  #shuffles the genes valus within cells,
  #intended to be applied before normalization
  for ( cell in c(1:ncol(dat)) ){
    rand <- sample(nrow(dat)) # generates random vector of numbers from colls
    dat[,cell] <- dat[rand,cell] # shuffles the genes within cells
    
  }# end of loop over cells
  return(dat)
}


```


```{r}
# add the umi counts to the meta data
chen2020_meta$umi <- as.numeric(colSums(chen2020_counts[,c(1:(dim(chen2020_counts)[2]-1) )])) # -1 because of the gene column

#keeps the cells we want, gets rid of the genes we dont want
chen2020_counts_kwongenes <- chenkwon.combined.counts[,colnames(chenkwon.combined.counts) %in% colnames(chen2020_counts)]


```

```{r}
FeaturePlot(mpfc_neurons.combined.sct, features = "Gad2", label = TRUE)
```
Clusters 0,1,2,3, and 6 are glutametergic excitatory cells.  CLusters 4and 5 are
gabanergic cells.  I am going to normalize before selecting cells for the first attempt.

```{r}
# doing it with the pavlab log2p1
chen_normed <- pavlab.normalize(chen2020_counts_kwongenes, 
                                median.scale = TRUE,
                                UMI = chen2020_meta$umi)

chen_normed <- data.frame(t(chen_normed))
colnames(chen_normed) <- rownames(chen2020_counts_kwongenes)
rownames(chen_normed) <- colnames(chen2020_counts_kwongenes)

# drop the labeling transcript to prevent teh classifier having an advantage it shouldn't have
chen_normed <- chen_normed[,!(names(chen_normed) %in% "TdTom-transgene")]

# remove engram label expression
chen_normed$Engramcell <- chen2020_meta$condition_label == "Fear-Recall" & chen2020_meta$engram_label == "tdT+"

glut_chen_normed <- chen_normed[chen2020_meta$BroadCellTypes =='Excitatory',]
glut_chen_normed$Engramcell <- as.factor(glut_chen_normed$Engramcell)
levels(glut_chen_normed$Engramcell) <- c("Inactive", "Active")

# chen.idents <- mpfc_neurons.combined.sct$seurat_clusters[colnames(chenkwon.combined.counts) %in% colnames(chen2020_counts)]

excitatory.chen.idx <- chen2020_meta$BroadCellTypes =='Excitatory'
# alternatively use this: chen.idents %in% c(0,1,2,3,6)


# For debugging the classifier
# test_data <- c(sample(rownames(chen.lognorm.glut[chen.lognorm.glut$Engramcell=="Inactive",]), 7), sample(rownames(chen.lognorm.glut[chen.lognorm.glut$Engramcell=="Active",]), 3))
# 
# test_data <- chen.lognorm.glut[test_data,]
```


```{r}
# resampled.regularizedRF.crossvalidated
classifier.Excitatory_mpfc <-  resampled.randomForest.crossvalidated( 
                                                     data=glut_chen_normed,
                                                     under.represented.class = "Active",
                                                     over.represented.class = "Inactive",
                                                     trees.total = 1000,
                                                     folds = 10,
                                                     proportion.each.batch=0.8,
                                                     batches.per.fold=20)

saveRDS(classifier.Excitatory_mpfc, "~/EngramCellModels/Excitatory_mpfc_remotememory_rfv1.RDS")
```


```{r}


#load model
classifier.Excitatory_mpfc <- readRDS("~/EngramCellModels/Excitatory_mpfc_remotememory_rfv1.RDS")

#Importance
importance.df.mpfc_excitatory<- data.frame(gene = as.character( rownames(classifier.Excitatory_mpfc$importance) ),
                                importance_score = as.numeric(classifier.Excitatory_mpfc$importance ) ) %>%
  arrange(desc(importance_score))

head(importance.df.mpfc_excitatory, 20) # don't forget to run this before gettng  the regularized
```

write_csv(importance.df.mpfc_excitatory,"mpfc_excitatory_remote_memory_gene_importance.csv")

Lets see if cell types have issues in them 
```{r}
# clusters, 0, 1,2, 3, 6 the Rorb+,Fam19a1+, Cck+, Cdh18, and Tshz2+ glutematergic neurons
# are what may have contrubted here

chen.markers <- read.csv('~/PavLabEngrams/EngramCellClassifier/Chen2020_GSE152632/Chen2020_ClusterMarkers.csv')


for (clust in c(0:3,6)){
  marker_genes <- mpfc_neurons_markers$gene[mpfc_neurons_markers$cluster==clust]
  marker_genes.idx <- importance.df.mpfc_excitatory$gene %in% marker_genes
  print( paste("Cluster", as.character(clust), sep ='') )
  print( mean(importance.df.mpfc_excitatory$importance_score[marker_genes.idx]) )
  print(" ")
}
```
It seems like generally the classifier is ignoring cluster markers.  If we try it with only the top 10 genes from each cell tyope I wonder what will happen.

```{r}

top10 <- mpfc_neurons_markers %>%
  group_by(cluster) %>%
  slice_max(n = 10, order_by = avg_log2FC)


for (clust in c(0:3,6)){
  marker_genes <- top10$gene[top10$cluster==clust]
  marker_genes.idx <- importance.df.mpfc_excitatory$gene %in% marker_genes
  print( paste("Cluster ", as.character(clust), sep ='') )
  print( mean(importance.df.mpfc_excitatory$importance_score[marker_genes.idx]) )
  print(" ")
}

```
Focusing on the top expressed genes does not change much.




```{r}


predictions <- as.numeric(predict(classifier.Excitatory_mpfc, 
                                  glut_chen_normed[,dim(glut_chen_normed)[2]],
                                  type="response"))

names(predictions) <- names(chen.lognorm.glut$Engramcell)

# the roc is quite good again, 
roc.engramcell = roc(chen.lognorm.glut$Engramcell,
                     predictions, 
                     plot=TRUE, legacy.axes=TRUE, percent=TRUE,
                     xlab="False Positive Percentage", ylab="True Postive Percentage", 
                     col="firebrick4", lwd=4, print.auc=TRUE)


roc.engramcell = roc(glut_chen_normed$Engramcell,
                     classifier.Excitatory_mpfc$votes[,2], 
                     plot=TRUE, legacy.axes=TRUE, percent=TRUE,
                     xlab="False Positive Percentage", ylab="True Postive Percentage", 
                     col="firebrick4", lwd=4, print.auc=TRUE)
```


```{r}
predictions <- as.numeric(predict(classifier.Excitatory_mpfc, 
                                  chen.lognorm.glut[,c(1:(dim(chen.lognorm.glut)[2]-1))],
                                  type="response"))
```



## Using td+ generally as a label

I want to see if the same results are maintained by usign the td+ label on it's own
as a marker.  

```{r}
# this normalization is across the whole dataset
# here instead of looking at only those cells active in 
# the fear recal task we use any positively labelled cell
chen.lognorm.glut.anypos <- glut_chen_normed
Activity_defintion <- chen2020_meta$engram_label == "tdT+"
chen.lognorm.glut.anypos$Engramcell <- Activity_defintion[excitatory.chen.idx]
chen.lognorm.glut.anypos$Engramcell <- as.factor(chen.lognorm.glut.anypos$Engramcell)
levels(chen.lognorm.glut.anypos$Engramcell) <- c("Inactive", "Active")

# For debugging the classifier
# test_data <- c(sample(rownames(chen.lognorm.glut[chen.lognorm.glut$Engramcell=="Inactive",]), 7), sample(rownames(chen.lognorm.glut[chen.lognorm.glut$Engramcell=="Active",]), 3))
# 
# test_data <- chen.lognorm.glut[test_data,]

chen_normed$Engramcell <-  chen2020_meta$engram_label == "tdT+"

glut_chen_normed_anypos <- chen_normed[chen2020_meta$BroadCellTypes =='Excitatory',]
glut_chen_normed_anypos$Engramcell <- as.factor(glut_chen_normed_anypos$Engramcell)
levels(glut_chen_normed_anypos$Engramcell) <- c("Inactive", "Active")


# had to switch the under vs over represented class
classifier.Excitatory_mpfc.anypos <-  resampled.randomForest.crossvalidated(
                                                     data= glut_chen_normed_anypos,
                                                     under.represented.class = "Inactive",
                                                     over.represented.class = "Active",
                                                     trees.total = 1000,
                                                     folds = 10,
                                                     proportion.each.batch=0.8,
                                                     batches.per.fold=20)


saveRDS(classifier.Excitatory_mpfc.anypos, "~/EngramCellModels/Excitatory_mpfc_anypositive_rf.RDS")
```


```{r}
#load model
classifier.Excitatory_mpfc.anypos <-  readRDS("~/EngramCellModels/Excitatory_mpfc_anypositive_rf.RDS")
# Importance

importance.df.mpfc_excitatory.anypos <- data.frame(gene = as.character( rownames(classifier.Excitatory_mpfc.anypos$importance) ),
                                importance_score = as.numeric(classifier.Excitatory_mpfc.anypos$importance ) ) %>%
  arrange(desc(importance_score))

head(importance.df.mpfc_excitatory.anypos, 100)
```

```{r}
predictions <- as.numeric(predict(classifier.Excitatory_mpfc.anypos, 
                                  glut_chen_normed_anypos[,c(1:(dim(glut_chen_normed_anypos)[2]-1))],
                                  type="response"))

names(predictions) <- names(glut_chen_normed_anypos$Engramcell)

# the roc is quite good again, 
roc.engramcell = roc(glut_chen_normed_anypos$Engramcell,
                     predictions, 
                     plot=TRUE, legacy.axes=TRUE, percent=TRUE,
                     xlab="False Positive Percentage", ylab="True Postive Percentage", 
                     col="firebrick4", lwd=4, print.auc=TRUE)
```

```{r}
# we now need the cell labels from our seurat integrated clustering
# so we need to align the index we are using for cell types
kwon.idx  <- (chenkwon.combined.meta$condition == 'Control') | (chenkwon.combined.meta$condition == 'CUS')


# if running teh clsutering script we do this alternatively we can laod the saved one
#kwon2021_meta$integrated_cluster <- mpfc_neurons.combined.sct@active.ident[kwon.idx]

# loading the sacved one...
integratedclustering.meta <- read.csv('~/PavLabEngrams/EngramCellClassifier/RemoteMemory/integrated_sct_clusters.csv', header = TRUE)

rownames(integratedclustering.meta) <- integratedclustering.meta$cell_id

kwon_integratedclusterids<- integratedclustering.meta[integratedclustering.meta$cell_id %in% colnames(kwon2021_counts),c('cluster',"cluster_num")]

chen_integratedclusterids<- integratedclustering.meta[integratedclustering.meta$cell_id %in% colnames(chen2020_counts),c('cluster',"cluster_num")]

```

```{r}
classifier.Excitatory_mpfc <- readRDS("~/EngramCellModels/Excitatory_mpfc_remotememory_rf.RDS")
```


```{r}

kwon2021_meta$umi <- colSums(kwon2021_counts[,c(1:18354)]) # minues 1 because the alst column contains gene games

kwon2021_counts <- chenkwon.combined.counts[,colnames(chenkwon.combined.counts) %in% colnames(kwon2021_counts)] 
kwon2021_counts[is.na(kwon2021_counts)] <- 0

kwon_normed <- pavlab.normalize(kwon2021_counts, 
                                UMI = kwon2021_meta$umi,
                                median.scale = TRUE)

kwon_normed <- data.frame(t(kwon_normed))
colnames(kwon_normed) <- rownames(kwon2021_counts)
rownames(kwon_normed) <- colnames(kwon2021_counts)

# from the file...
# integratedclustering.meta <- read.csv('~/PavLabEngrams/EngramCellClassifier/RemoteMemory/integrated_sct_clusters.csv', header = TRUE)
kwon.glut.idx <- kwon_integratedclusterids$cluster %in% c("Rorb", "Fam19a1", "Cck", "Cdh18", "Tshz2")



# for inhibitory neurons
#("Sst", "Vip")

kwon_mpfc.log.glut <- kwon_normed[kwon.glut.idx,]
#kwon_mpfc.log.glut$Engramcell <- 

# make predictions
predict.kwon <- predict(classifier.Excitatory_mpfc, kwon_mpfc.log.glut, type = 'prob')
predict.kwon <- data.frame(predict.kwon)
predict.kwon$celltype <- kwon_integratedclusterids$cluster[kwon.glut.idx]
predict.kwon$condition <- kwon2021_meta$condition[kwon.glut.idx]
```

Visaulize the distribution of engram probablility
```{r}
p <- ggplot(data = predict.kwon, aes(x=Active) )


jpeg("Histogram_RemoteActivatyScore.jpg", width = 350, height = 350)
p + geom_histogram(color = "darkgreen", fill = "lightgreen") + theme_classic() +
  xlab("Probability of being an Engram Cell") +
  ylab("Counts") 
dev.off()
```





There are more glutametergic cells predicted to be active in the chronic stress condition.
How ever overall these cells are not as rare compared to recently active cells.

```{r}
# > sum(predict.kwon$Active[predict.kwon$condition=="Control"]>0.5)
# [1] 2827
# > sum(predict.kwon$Active[predict.kwon$condition=="CUS"]>0.5)
# [1] 3556
# > mean(predict.kwon$Active[predict.kwon$condition=="Control"]>0.5)
# [1] 0.3040112
# > mean(predict.kwon$Active[predict.kwon$condition=="CUS"]>0.5)
# [1] 0.3484225
```






```{r}
predict.kwon$RemoteMemoryCell <- predict.kwon$Active>=0.5
predict.kwon$sample <- kwon2021_meta$mouse.replicate[kwon.glut.idx]
```

Making frequency table

```{r}
kwonpredictions.frequency <- predict.kwon[,c(3:6)]

kwonpredictions.frequency <- data.frame(table(kwonpredictions.frequency))

# we need to remove the gabanergic entries, preserved because they are factors
kwonpredictions.frequency <- kwonpredictions.frequency[!((kwonpredictions.frequency$celltype == 'Sst') | (kwonpredictions.frequency$celltype == 'Vip')),]

#we need to remove rows representing samples which were not in that condition
# i.e. cell from mouse replicate 30 in the CUS condition, becuase those do not exist, rep30 was in control
# these entries have zero cells so can be filtered that way
kwonpredictions.frequency <- kwonpredictions.frequency[kwonpredictions.frequency$Freq>0,]

#fialed first attempt
#df <- df[!((df$condition == 'CUS') | (df$sample ==  c('Rep30','Rep31','Rep33','Rep34') )),]
#df <- df[!((df$condition == 'Control') | (df$sample ==  c('Rep45','Rep46','Rep48','Rep49') )),]
kwonpredictions.frequency$celltype <- as.factor(kwonpredictions.frequency$celltype)
kwonpredictions.frequency$condition <- as.factor(kwonpredictions.frequency$condition)
kwonpredictions.frequency$RemoteMemoryCell <- as.factor(kwonpredictions.frequency$RemoteMemoryCell)
kwonpredictions.frequency$sample <- as.factor(kwonpredictions.frequency$sample)
```

# Visualizing frequncy table



## Training regression models on this to indentify if there is an effect on cell count

First we will use some linerar regression though i feel the question is more suited to
logistic regression.

```{r}
linmodel <- lm(formula=Freq~condition*celltype*RemoteMemoryCell,
               data = kwonpredictions.frequency)
summary(linmodel)
```



# mixed effects model
```{r}
mixedmodel <- lmer(formula =Freq ~ 1 + (1|sample) + celltype*condition*RemoteMemoryCell,
              data = df)
summary(mixedmodel)
```

Trying again with a different formulation, this will include a random effect intereaction with
celltype to account for sample specific variations in it.

```{r}
mixedmodel2 <- lmer(formula =Freq ~ 1 + (1|sample:celltype) + celltype*condition*RemoteMemoryCell,
              data = df)
summary(mixedmodel2)
```

Attempting now with logistic regression
based on this tutorial https://stats.oarc.ucla.edu/r/dae/logit-regression/
```{r}
logregmodel <- glm(RemoteMemoryCell ~ condition + celltype, 
                   data = df, family = "binomial")
summary(logregmodel)
```



Now including interactions
```{r}
logregmodel2 <- glm(RemoteMemoryCell ~ condition * celltype, 
                   data = df, family = "binomial")
summary(logregmodel2)
```


```{r}
logregmodel3 <- glm(RemoteMemoryCell ~ sample*condition * celltype, 
                   data = df, family = "binomial")
summary(logregmodel3)
```

One last go with a rediculously simpl model
```{r}
logregmodel4 <- glm(RemoteMemoryCell ~ condition, 
                   data = df, family = "binomial")
summary(logregmodel4)
```




## With context only cells

```{r}
# this normalizaition is across the whole dataset
# here instead of looking at only those cells active in 
# the fear recal task we use any positively labelled cell
chen.lognorm.glut.nofear <- chen.lognorm.glut
Activity_defintion <- chen2020_meta$condition_label == "Context-Only" & chen2020_meta$engram_label == "tdT+"
chen.lognorm.glut.nofear$Engramcell <- Activity_defintion[excitatory.chen.idx]
chen.lognorm.glut.nofear$Engramcell <- as.factor(chen.lognorm.glut.nofear$Engramcell)
levels(chen.lognorm.glut.nofear$Engramcell) <- c("Inactive", "Active")

classifier.Excitatory_mpfc.nofear <-  resampled.randomForest.crossvalidated(
                                                     data= chen.lognorm.glut.nofear,
                                                     under.represented.class = "Active",
                                                     over.represented.class = "Inactive",
                                                     trees.total = 1000,
                                                     folds = 10,
                                                     proportion.each.batch=0.8,
                                                     batches.per.fold=20)

# Importance

importance.df.mpfc_excitatory<- data.frame(gene = as.character( rownames(classifier.Excitatory_mpfc$importance) ),
                                importance_score = as.numeric(classifier.Excitatory_mpfc$importance ) ) %>%
  arrange(desc(importance_score))

head(importance.df.mpfc_excitatory, 100)
```


## Chen DEGs


```{r}
chen2020_meta[, c("source_name", "broad_cell_types", "engram_label")]
```


```{r}
mask_names <- unique(chen2020_meta[, c("source_name", "broad_cell_types", "engram_label")])

# Create masks
for (i in 1:nrow(mask_names)) {
  assign(paste0("mask_", i), chen2020_meta$source_name == mask_names$source_name[i] & 
    chen2020_meta$broad_cell_types == mask_names$broad_cell_types[i] & 
    chen2020_meta$engram_label == mask_names$engram_label[i])
}

# Print names of masks and sum of each masks values
for (i in 1:nrow(mask_names)) {
  print(paste0("mask_", i))
  print(sum(get(paste0("mask_", i))))
}
```








## Trying a Logistic regression model instead

```{r}
# Smote https://www.statology.org/smote-in-r/
# https://rdrr.io/cran/ROSE/man/ROSE-package.html
# multiclass classification in randomForest

# Loading package
library(caTools)
library(ROCR) 
library(groupdata2)
   
# Splitting dataset with group data2
# find idents of all chen cells
chen.idents <- mpfc_neurons.combined.sct@active.ident[colnames(chenkwon.combined.counts) %in% colnames(chen2020_counts)]

table(mpfc_neurons.combined.sct@active.ident[colnames(chenkwon.combined.counts) %in% rownames(chen.lognorm.glut)])

excitatory.chen.idx <- chen.idents[chen.idents %in% c("Rorb","Fam19a1","Cck","Cdh18","Tshz2")]
excitatory.chen.idx <- colnames(chenkwon.combined.counts) %in% rownames(chen.lognorm.glut)
# get the index of glutametergic chen cells in seurat object with labels
glut.seurat.idx <- rownames(mpfc_neurons.combined.sct@meta.data) %in% rownames(chen.lognorm.glut)
# use th index to pull celltype, label, and the active (td+ in fear recal)
cell_type_df <- data.frame( celltype = mpfc_neurons.combined.sct@active.ident[excitatory.chen.idx])
cell_type_df$label_status <- mpfc_neurons.combined.sct@meta.data$label_status[excitatory.chen.idx]
cell_type_df$Active <- chen.lognorm.glut$Engramcell
cell_type_df$cell_id <- rownames(chen.lognorm.glut)
# groupdata2 vinette
# https://cran.r-project.org/web/packages/groupdata2/vignettes/cross-validation_with_groupdata2.html#:~:text=groupdata2%20functions%20in%20focus,-partition()%20creates&text=fold()%20creates%20(optionally)%20balanced,participant_id)%20in%20the%20same%20fold.

# now we partition by td+fear recall cells, active, with balanced cell types
# we don't need to worry about the conditions
balanced_partitions <- partition( cell_type_df, p = 0.3, cat_col = 'Active')

train_data <- chen.lognorm.glut[balanced_partitions[[1]]$cell_id,]
test_data <- chen.lognorm.glut[balanced_partitions[[2]]$cell_id,]

# Training model
logistic_model <- glm(Engramcell ~ ., 
                      data = train_data, 
                      family = "binomial")
logistic_model
   
# Summary
summary(logistic_model)
   
# Predict test data based on model
predict_reg <- predict(logistic_model, 
                       test_reg, type = "response")
predict_reg  
   
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
   
# Evaluating model accuracy
# using confusion matrix
table(test_reg$vs, predict_reg)
   
missing_classerr <- mean(predict_reg != test_reg$vs)
print(paste('Accuracy =', 1 - missing_classerr))
   
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$vs) 
ROCPer <- performance(ROCPred, measure = "tpr", 
                             x.measure = "fpr")
   
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
   
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE, 
     print.cutoffs.at = seq(0.1, by = 0.1), 
     main = "ROC CURVE")
abline(a = 0, b = 1)
   
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
```
  Plan for multiclass classifier: 
  1) input will be metadata containing engram label, cell type, and cell_id
  2) partition() or other group data for cross validation
  3) upsample in each fold to get matching number of cells types
  4) upsample the active cell type
  5) only keep the cell ids from the previous steps
  6) generate the training and test data for each fold
  from this list of cell ids normalized_data[cell_id_fold[i]]
  7) train multiclass randomForest
  8) calculate the predictions and performance, store the confusion matrix
  9) merge model
  10) repeat




### Caret multi-class classifier to deal with cell types

There is an uneven distribution of labelled neurons within these clusters.
```{r}
clustercellcount.table<-table(mpfc_neurons.combined.sct@active.ident,mpfc_neurons.combined.sct@meta.data$label_status)
clustercellcount.table
```


```{r}
percentcells.table <- clustercellcount.table

for(i in c(1:3)){
  percentcells.table[,i] <- (percentcells.table[,i]/sum(percentcells.table[,i]) )*100
  percentcells.table[,i] <- round(percentcells.table[,i], 1)
}
percentcells.table

```

```{r}
kwon.idx <- mpfc_neurons.combined.sct@meta.data$label_status=="discovery_data"

clustercellcount.table.kwon <-table(mpfc_neurons.combined.sct@active.ident[kwon.idx],mpfc_neurons.combined.sct@meta.data$condition[kwon.idx])

percentcells.table.kwon <- clustercellcount.table.kwon

for(i in c(1:2)){
  percentcells.table.kwon[,i] <- (percentcells.table.kwon[,i]/sum(percentcells.table.kwon[,i]) )*100
  percentcells.table.kwon[,i] <- round(percentcells.table.kwon[,i], 1)
}
percentcells.table.kwon

```
So while in the chen data set the FACS processing seems to have screwed up the percentage of cells in the data, the Kwon dataset pretty much has the same abundances of these cell types.  


```{r}
table(mpfc_neurons.combined.sct@meta.data$condition,
      mpfc_neurons.combined.sct@active.ident, 
      mpfc_neurons.combined.sct@meta.data$label_status)
```


```{r}
#Attempting to use caret

Activity_defintion <- chen2020_meta$condition_label == "Fear-Recall" & chen2020_meta$engram_label == "tdT+"
chen.lognorm$Engramcell <- Activity_defintion
chen.lognorm$Engramcell <- as.factor(chen.lognorm$Engramcell)
levels(chen.lognorm$Engramcell) <- c("Inactive", "Activated")


Activity_defintion <- as.character(sapply(c(1:3530), 
                             function(x) paste(as.character(chen.lognorm$Engramcell[x]), mpfc_neurons.combined.sct@active.ident[chenkwon.combined.meta$label_status!="discovery_data"][x],
                                               sep="_")  ) )

Activity_defintion <- as.character(lapply(Activity_defintion, function(x) if(grepl("Inactive", x, fixed=TRUE)) "Inactive" else x) )

table(Activity_defintion)

chen.lognorm$Engramcell <- as.factor(Activity_defintion)


# caret
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = multiClassSummary,
                     #classProbs = TRUE,
                     ## new option here:
                     sampling = "up")

model_with_up_sample <- train(Engramcell ~ ., data = chen.lognorm,
                                method = "ordinalRF",
                                preProcess = c("range"),
                                verbose = FALSE,
                                trControl = ctrl)

# I fyou get the error : Error: protect(): protection stack overflow
# run...
# options(expressions = 5e5)

# caret tutorial using random forest:
# https://www.machinelearningplus.com/machine-learning/caret-package/

# multi class classfication in caret
# https://stats.stackexchange.com/questions/453259/multi-class-probabilities-of-random-forest-inside-caret-model

# cv and resampling
# https://stackoverflow.com/questions/45250252/how-to-downsample-using-r-caret

# cv stakc question in caret just for good measure
# https://stackoverflow.com/questions/22909197/creating-folds-for-k-fold-cv-in-r-using-caret

# how to do it in random forest
# https://rpubs.com/jkylearmstrong/RF_Imputation_Multi_class


```


Saving and loading the model
```{r}
file_name <- "classifierExcitatory_mpfc.rds"
saveRDS(classifier.Excitatory_mpfc, file_name)
#readRDS("model_rf.RDS")
```

```{r}

readRDS("classifierExcitatory_mpfc.rds")

```





### Regularizing the Classifier

The previous classifer had disapointingly low importance scores for the genes and a suspisciously good AUC.  I am curious if regularization could help this.
```{r}
# resampled.regularizedRF.crossvalidated
classifier.Excitatory_mpfc.reg <-  resampled.regularizedRF.crossvalidated( data= chen.lognorm.glut,
                                                     under.represented.class = "Active",
                                                     over.represented.class = "Inactive",
                                                     trees.total = 1000,
                                                     folds = 10,
                                                     proportion.each.batch=0.8,
                                                     batches.per.fold=20)

```


```{r}
importance.df.mpfc_excitatory.reg <- data.frame(gene = as.character( rownames(classifier.Excitatory_mpfc.reg$importance) ),
                                importance_score = as.numeric(classifier.Excitatory_mpfc.reg$importance) ) %>%
  arrange(desc(importance_score))

head(importance.df.mpfc_excitatory.reg , 100) # don't forget to run this before getting  the regularized
```

```{r}
predictions <- as.numeric(predict(classifier.Excitatory_mpfc.reg, 
                                  chen.lognorm.glut[,c(1:(dim(chen.lognorm.glut)[2]-1))],
                                  type="response"))

names(predictions) <- names(chen.lognorm.glut$Engramcell)

# the roc is quite good again, 
roc.engramcell = roc(chen.lognorm.glut$Engramcell,
                     predictions, 
                     plot=TRUE, legacy.axes=TRUE, percent=TRUE,
                     xlab="False Positive Percentage", ylab="True Postive Percentage", 
                     col="firebrick4", lwd=4, print.auc=TRUE)
```




```{r}
for (clust in c(0:3,6)){
  marker_genes <- mpfc_neurons_markers$gene[mpfc_neurons_markers$cluster==clust]
  marker_genes.idx <- importance.df.mpfc_excitatory.reg$gene %in% marker_genes
  print( paste("Cluster ", as.character(clust), sep ='') )
  print( mean(importance.df.mpfc_excitatory.reg$importance_score[marker_genes.idx]) )
  print(" ")
}

```


```{r}
top10 <- mpfc_neurons_markers %>%
  group_by(cluster) %>%
  slice_max(n = 10, order_by = avg_log2FC)


for (clust in c(0:3,6)){
  marker_genes <- top10$gene[top10$cluster==clust]
  marker_genes.idx <- importance.df.mpfc_excitatory.reg$gene %in% marker_genes
  print( paste("Cluster ", as.character(clust), sep ='') )
  print( mean(importance.df.mpfc_excitatory.reg$importance_score[marker_genes.idx]) )
  print(" ")
}
```

Not seeing much difference here though there are some slight differences


