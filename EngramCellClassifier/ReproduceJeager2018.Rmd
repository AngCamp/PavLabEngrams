---
title: "Reporducing Jeager et al. (2018)"
author: "Angus Campbell"
date: "16/01/2022"
output: html_document
---

https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet

```{r message=FALSE, include=FALSE}
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
```

INTORDUCTION
---
  We will attempt to reproduce some of the analyses in [Jeager et al., 2018](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6079101/).  We are of course espescially interested in the classifier in figure 6C with the 
  
  
LOADING THE DATA
---

```{r}
# Jeager et al., (2018) meta data and tpm

jeager2018_tpm <- bind_cols(read.table('Jeager2018_GSE98679/GSE98679_tpm.txt.gz', header = TRUE, check.names = FALSE),
                               read.table('Jeager2018_GSE98679/GSE98679_v2_GSM3308862-GSM3309413_tpm.txt.gz', header = TRUE, check.names = FALSE))

#We are using the tpms provided to skip some of the filtering steps, but if desreed here's where they are.
#There are 2581 genes excluded after filtering.
#
# jeager2018_counts <- bind_cols(read.table('Jeager2018_GSE98679/GSE98679_count.txt.gz', header = TRUE, check.names = FALSE),
#                                read.table('Jeager2018_GSE98679/GSE98679_v2_GSM3308862-GSM3309413_count.txt.gz', header = TRUE, check.names = FALSE))

```

```{r}

jeager2018_meta <- read.csv('Jeager2018_GSE98679/SraRunTable.txt', header = TRUE)
jeager2018_meta = jeager2018_meta[c(1:46,599:912,47:598),] #we need to fix Jeager's files up a bit
rownames(jeager2018_meta) <- c(1:912)

# blank.to.DG <-function(x){
#   if(x==""){
#     x="DG"
#   }
# }
jeager2018_meta$predicted_cell_type <- as.character(lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x}))

jeager2018_meta$predicted_cell_type <- lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x})

#ditch mousingle_number, put it into Mouse_Number
jeager2018_meta$Mouse_Number[361:912] <- jeager2018_meta$mousingle_number[361:912]
jeager2018_meta <- jeager2018_meta[,c(1:33,35,36)]



```

Active DG neurons exhibit a dramatic shift in transcription
---

The thresholding for this first session is described as "Nuclei were excluded as outliers based on total aligned reads and total gene count, or extreme-outliers, based on clustering (Supplementary Fig 2a–b). An average of 1.17 million reads were aligned per nucleus, with an average of 5637 genes detected above a log2(TPM+1) (TPM) = 1."

```{r}

meangenecounts <- function(tpm.df){
  test <- log(tpm.df+1, 2)>1 #log base 2 tpm counts +1 over 1
  return(mean(as.numeric(colSums(test, na.rm = TRUE)))) 
}

print("Average gene's passing threshold per cell:")
print(meangenecounts(jeager2018_tpm[,c(1:360)])) 
print("Total missing entries in first dataset:")
print(sum(is.na(jeager2018_tpm[,c(1:360)]))) 
```

I know some of the nuclei in the data set were considered outliers.  Maybe this is part of the discrepancy?  After all 912 nuclei are included in the data but only 868 were used as per the methods section  "The final cutoffs were 100,000 total aligned reads and 4000 total genes detected. Nuclei below these thresholds were detected as outliers and removed from further analysis. A total of 967 nuclei were used for this study, with 868 (89.8%) surviving the filtering thresholds".

I don't have access to the total aligned reads but I can check for genes.  I will look for na values or 0 reads of a gene

```{r}
test <- sapply(jeager2018_tpm[,c(1:360)], function(y) sum(length(which(is.na(y)))))
print(summary(test))
```

SO for the most part missing genes is a pretty minimal problem. We will switch to using counts rather than tpm for the next section to test if there are sufficient genes in each cell.

```{r}
#testing for cells with genes under 4000

test2 <- sapply(jeager2018_counts[,c(1:360)], function(y) sum(length(which(y>0))))

# which(test2<4000)
# X151207_E12_N_C_F_EE_2 X151207_H12_N_C_F_EE_2  X151214_F1_P_C_N_EE_3  X151214_H1_P_C_N_EE_3 X151214_H11_P_C_F_EE_3             X160107_07 
#                     49                     83                    123                    137                    139                    199 
#             X160107_08             X160107_22             X160107_23             X160107_29             X160118_09             X160118_14 
#                    200                    214                    215                    221                    249                    254 
#             X160118_16             X160118_17             X160118_21             X160118_27             X160118_28             X160118_29 
#                    256                    257                    261                    267                    268                    269 
#             X160118_30             X160118_31 
#                    270                    271 

# > length(which(test2>4000))
# [1] 340
```

So that leaves us with 340 cells, which is a believebale number cosidering we should be eliminating 44 cells eventually.  Remeber this is only in the first 360 cells, we are not including the v2 dataset (timecourse, reactivation data).  But what is worrying to me is that the whihc seems to be printing names of cells that are in the v2 dataset.

Also minor note but we are looking for counts there greater than 0 itest it with >1 as well see if it makes a difference.

FILTERING AS PER THE METHODS
---





THE CLASSIFIER IN SIGNATURE ESTABLISHED OVER 4H SELECT REACTIVATED NEURONS
---

From Jeager et al. (2018):  "A receiver-operating characteristics (ROC) curve showed that the model successfully called Reactivated neurons with an area under the curve of 0.93 and 0.96 when compared to either the Newly Activated (model i) or Not Reactivated (model ii) nuclei, respectively (Fig. 6c), and when the model was tasked with distinguishing all three groups simultaneously, classification errors of 13%, 20%, and 20% were calculated for Reactivated, Not Reactivated, and Newly Activated nuclei, respectively."

Notes on which nuclei to include:  "DEGs between Reactivated and Not Reactivated nuclei (FDR < 0.05) were filtered to maintain only those with expression in at least 80% of Reactivated nuclei, for upregulated genes, or at most 40% of Reactivated nuclei for downregulated genes where the cutoff for expression was placed at 1 log2(TPM+1). Genes were further excluded if they contained any association with batch effect or were differentially expressed in the 1-h vs HC comparison. The remaining 191 genes were passed through an initial round of feature elimination. A pairwise classification between Reactivated and either Newly Activated or Not Reactivated nuclei used a random forest classifier with a binomial family and 10,000 trees (R statistical package randomForest78. ROC curves were calculated by training on 15 nuclei per condition and testing on the remaining hold out samples, then calculating sensitivity and specificity using the R statistical package ROCR81. The genes with the top importance (Mean Decrease Gini > 0.4) in each of the pairwise comparisons were then pooled and the random forest procedure was used with a binomial family and 10,000 trees to classify all three conditions together. The classification error rate of this model was reported. This model was then used to predict the presence of a Reactivated gene signature using the 4- and 5-h time points using the base R stats predict function."

-it is not described what an association with batch effect means



References

Jaeger, B. N., Linker, S. B., Parylak, S. L., Barron, J. J., Gallina, I. S., Saavedra, C. D., ... & Gage, F. H. (2018). A novel environment-evoked transcriptional signature predicts reactivity in single dentate granule neurons. Nature communications, 9(1), 1-15.

