xlab(axislabs[1]) +
ylab(axislabs[2]) +
theme(plot.title = element_text(hjust = 0.5))
p
CA1dat <-filteredDat[filteredDat$celltype=="CA1", c(1:40221,40223)]
#using FactoMineR PCA function
pcs <- PCA(CA1dat,
quali.sup=c(40222), #to identify fos status
graph = FALSE)
#putting pcs into our dataframe
CA1dat$pc1 <- pcs$ind$coord[, 1]
CA1dat$pc2 <- pcs$ind$coord[, 2]
#calls pcs object to get variences rounds them to 2nd digit makes string for axis labels
axislabs <-c(paste("PC1 (", as.character(round(pcs$eig[1,2],2)),"% of varience)", sep =''),
paste("PC2 (", as.character(round(pcs$eig[2,2],2)),"% of varience)", sep =''))
p <- ggplot(data = CA1dat, aes(x = pc1, y = pc2, color = fos_status)) +
geom_point()  +
labs(title='PCs and Fos Status of CA1 Neurons',
color= 'Fos Status') +
xlab(axislabs[1]) +
ylab(axislabs[2]) +
theme(plot.title = element_text(hjust = 0.5))
p
VIPdat <-filteredDat[filteredDat$celltype=="VIP", c(1:40221,40223)]
#using FactoMineR PCA function
pcs <- PCA(VIPdat,
quali.sup=c(40222), #to identify fos status
graph = FALSE)
#putting pcs into our dataframe
VIPdat$pc1 <- pcs$ind$coord[, 1]
VIPdat$pc2 <- pcs$ind$coord[, 2]
#calls pcs object to get variences rounds them to 2nd digit makes string for axis labels
axislabs <-c(paste("PC1 (", as.character(round(pcs$eig[1,2],2)),"% of varience)", sep =''),
paste("PC2 (", as.character(round(pcs$eig[2,2],2)),"% of varience)", sep =''))
p <- ggplot(data = VIPdat, aes(x = pc1, y = pc2, color = fos_status)) +
geom_point()  +
labs(title='PCs and Fos Status of VIP+ Gabanergic neurons',
color= 'Fos Status') +
xlab(axislabs[1]) +
ylab(axislabs[2]) +
theme(plot.title = element_text(hjust = 0.5))
p
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(Rtsne)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
getwd()
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
colnames(chen2020_counts)
colnames(chen2020_counts)[1001:2001]
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
View(chen2020_meta)
colnames(chen2020_counts)[1:10]
rownames(chen2020_counts) <- chen2020$X
rownames(chen2020_counts) <- chen2020_counts$X
dim(chen2020_counts)
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
View(chen2020_meta)
table(chen2020_meta$engram_label)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
getwd()
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(Rtsne)
library(dplyr)
library(Seurat)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rownames(chen2020_counts) <- chen2020_counts$X
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
#one row is missing in the metadata
underexpressedgenes <- rownames(chen2020_counts)[which(table(which(chen2020_counts==0, arr.ind = TRUE)[,1])>(3530-5))]
dim(chen2020_counts)
underexpressedgenes <- which(table(which(chen2020_counts==0, arr.ind = TRUE)[,1])>(3530-5))
test <- c(1:23355)
test <- test[!test %in% underexpressedgenes]
test[88]
chen2020_counts <- chen2020_counts[!c(1:23355) %in% underexpressedgenes,]
tdTpos <- chen2020_counts[,which(chen2020_meta$engram_label=="tdT+")]
tdTneg <- chen2020_counts[,which(chen2020_meta$engram_label=="tdT-")]
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
getwd()
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(Rtsne)
library(dplyr)
library(Seurat)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rownames(chen2020_counts) <- chen2020_counts$X
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
#one row is missing in the metadata
underexpressedgenes <- which(table(which(chen2020_counts==0, arr.ind = TRUE)[,1])>(3530-5))
library(Seurat)
data("pbmc_small")
pbmc_small
# As CCA requires two datasets, we will split our test object into two just for this example
pbmc1 <- subset(pbmc_small, cells = colnames(pbmc_small)[1:40])
pbmc2 <- subset(pbmc_small, cells = colnames(x = pbmc_small)[41:80])
pbmc1[["group"]] <- "group1"
pbmc2[["group"]] <- "group2"
pbmc_cca <- RunCCA(object1 = pbmc1, object2 = pbmc2)
# Print results
print(x = pbmc_cca[["cca"]])
str(pbmc_cca)
str(pbmc_small)
chenCCA <- RunCCA(tdTpos, tdTneg, compute.gene.loadings=TRUE)
tdTpos <- chen2020_counts[,which(chen2020_meta$engram_label=="tdT+")]
tdTneg <- chen2020_counts[,which(chen2020_meta$engram_label=="tdT-")]
chenCCA <- RunCCA(tdTpos, tdTneg, compute.gene.loadings=TRUE)
rownames(chen2020_meta) <- colnames(chen2020_counts)
chen2020 <- CreateSeuratObject(counts = chen2020_counts,
meta.data = chen2020_meta)
tdTpos.idx <- which(chen2020_meta$engram_label=="tdT+")
tdTneg.idx <- which(chen2020_meta$engram_label=="tdT-")
engram.cells <- subset(chen2020, cells = colnames(chen2020)[tdTpos.idx])
nonengram.cells <- subset(chen2020, cells = colnames(x = chen2020)[tdTneg.idx])
chenCCA <- RunCCA(engram.cells, nonengram.cells, compute.gene.loadings=TRUE)
chenCCA <- RunCCA(engram.cells, nonengram.cells)
str(engram.cells)
chen2020 <- CreateSeuratObject(counts = chen2020_counts)
engram.cells <- subset(chen2020, cells = colnames(chen2020)[tdTpos.idx])
nonengram.cells <- subset(chen2020, cells = colnames(x = chen2020)[tdTneg.idx])
chenCCA <- RunCCA(engram.cells, nonengram.cells)
engram.cells[["group"]] <- "group1"
nonengram.cells[["group"]] <- "group2"
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells)
rlang::rtrace
rlang::trace_back()
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells)
rlang::trace_back()
engram.cells <- subset(chen2020, cells = colnames(chen2020)[tdTpos.idx])
nonengram.cells <- subset(chen2020, cells = colnames(chen2020)[tdTneg.idx])
engram.cells[["group"]] <- "group1"
nonengram.cells[["group"]] <- "group2"
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells)
rlang::trace_back()
rlang::last_error()
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells)
rlang::last_error()
str(engram.cells)
?RunCCA
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells,
features = VariableFeatures(object = chen2020))
chenCCA <- RunCCA(object1 = engram.cells, object2 = nonengram.cells,
features = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
getwd()
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(Rtsne)
library(dplyr)
library(Seurat)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rownames(chen2020_counts) <- chen2020_counts$X
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
underexpressedgenes <- which(table(which(chen2020_counts == 0, arr.ind = TRUE)[,1])>(3530-5))
chen2020_counts <- chen2020_counts[!c(1:23355) %in% underexpressedgenes,]
rownames(chen2020_meta) <- colnames(chen2020_counts)
tdTpos.idx <- which(chen2020_meta$engram_label=="tdT+")
tdTneg.idx <- which(chen2020_meta$engram_label=="tdT-")
#library(Seurat)
chen2020 <- CreateSeuratObject(counts = chen2020_counts)
,
str(chen2020)
2
chen2020$orig.ident
chen2020 <- CreateSeuratObject(counts = log(chen2020_counts)+1,
meta.data = chen2020_meta)
chen2020 <- FindVariableFeatures(chen2020)
chen2020 <- CreateSeuratObject(counts = log(chen2020_counts)+1,
meta.data = chen2020_meta)
chen2020 <- CreateSeuratObject(counts = log(chen2020_counts)+1)
chen2020 <- FindVariableFeatures(chen2020)
sum(is.na(chen2020_counts))
is.na(chen2020_counts)
is.na?
?is.na()
View(chen2020_meta)
table(chen2020_meta)
table(chen2020_meta$source_name)
library(Seurat)
library(SeuratData)
library(patchwork)
install.packages("SeuratData")
library(installr)
updateR()
library(devtools)
devtools::install_github('satijalab/seurat-data')
library(SeuratData)
test <- FindVariableFeatures(chen2020, selection.method = "vst", nfeatures = 3530)
head(chen2020$nFeature_RNA)[1:4,1:4]
head(chen2020$nFeature_RNA)
head(chen2020$nCount_RNA)
log(chen2020_counts)+1
test <- log(chen2020_counts)+1
View(test)
rm(counts)
rm(chen2020)
chen2020 <- CreateSeuratObject(counts = chen2020_counts,
meta.data = chen2020_meta)
test <- FindVariableFeatures(chen2020, selection.method = "vst", nfeatures = 3530)
View(temp)
View(test)
colnames(test[[1]])
test[[1]]
str(test)
test@assays$RNA
test <- FindVariableFeatures(chen2020, selection.method = "mean.var.plot")
rm(test)
# in the tutorial they chose 2000, I just chose to match the number of cells we had
chen2020 <- ScaleData(chen2020)
?ScaleData
#library(Seurat)
chen2020 <- CreateSeuratObject(counts = chen2020_counts)
chen2020 <- FindVariableFeatures(chen2020, selection.method = "vst", nfeatures = 3530) #no idea how I chose 3530,
# in the tutorial they chose 2000, I just chose to match the number of cells we had
chen2020 <- ScaleData(chen2020)
#library(Seurat)
chen2020 <- CreateSeuratObject(counts = chen2020_counts)
#meta.data = chen2020_meta)
chen2020 <- FindVariableFeatures(chen2020, selection.method = "vst", nfeatures = 3530) #no idea how I chose 3530,
# in the tutorial they chose 2000, I just chose to match the number of cells we had
chen2020nobatch <- ScaleData(chen2020)
chen2020 <-
test = RunPCA(chen2020nobatch, features = VariableFeatures(chen2020))
test = RunPCA(chen2020nobatch, features = VariableFeatures(chen2020))
table(chen2020_meta$source_name)
library(Seurat)
library(SeuratData)
library(patchwork)
library(metap)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
getwd()
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
library(tidyverse)
library(GEOquery)
library(AnnotationDbi)
library(randomForest)
library(data.table)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(Rtsne)
library(dplyr)
library(Seurat)
library(stringr)
hen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rm(hen2020_counts)
chen2020_counts <- read.csv('Chen2020_GSE152632/GSE152632_GEO_mberkchen_TRAP2_counts.csv.gz', header = TRUE)
rownames(chen2020_counts) <- chen2020_counts$X
chen2020_counts <- chen2020_counts[,2:3531]
chen2020_meta <- read.csv( 'Chen2020_GSE152632/SraRunTable.txt', header = TRUE)
chen2020_meta$engram_label <-  as.factor(sapply(as.character(colnames(chen2020_counts)), function(y) if (grepl("_pos_", y, fixed=TRUE)) "tdT+" else "tdT-"))
condition_label <- chen2020_meta$source_name %>%
sapply( function(y) if (grepl("Homecage", y, fixed=TRUE)) "Homecage")
condition_label <- chen2020_meta$source_name
condition_label[str_detect(condition_label, "Homecage")] = "Homecage"
condition_label[str_detect(condition_label, "Context-Only")] = "Context-Only"
condition_label[str_detect(condition_label, "Fear-Only")] = "Fear-Only"
condition_label[str_detect(condition_label, "Fear-Recall")] = "Fear-Recall"
chen2020_meta$condition_label <- condition_label
rm(condition_label)
condition_label <- as.character(sapply(condition_label, function(y) if (grepl("Homecage", y, fixed=TRUE)) "Homecage"))
condition_label <- chen2020_meta$source_name
condition_label[str_detect(condition_label, "Homecage")] = "Homecage"
condition_label[str_detect(condition_label, "Context-Only")] = "Context-Only"
condition_label[str_detect(condition_label, "Fear-Only")] = "Fear-Only"
condition_label[str_detect(condition_label, "Fear-Recall")] = "Fear-Recall"
chen2020_meta$condition_label <- condition_label
condition_label <- as.character(sapply(condition_label, function(y) if (grepl("Homecage", y, fixed=TRUE)) "Homecage"))
condition_label <- sapply(rownames(condition_label), function(y) if (grepl("Context-Only", y, fixed=TRUE)) "Context-Only")
View(chen2020_meta)
condition_label <- chen2020_meta$source_name
condition_label[str_detect(condition_label, "Homecage")] = "Homecage"
condition_label[str_detect(condition_label, "Context-Only")] = "Context-Only"
condition_label[str_detect(condition_label, "Fear-Only")] = "Fear-Only"
condition_label[str_detect(condition_label, "Fear-Recall")] = "Fear-Recall"
chen2020_meta$condition_label <- condition_label
jeager2018 <- CreateSeuratObject(counts = jeager2018_counts)
jeager2018 <- FindVariableFeatures(jeager2018, selection.method = "vst", nfeatures = 3530) #no idea how I chose 3530,
# in the tutorial they chose 2000, I just chose to match the number of cells we had
#jeager2018nobatch <- ScaleData(jeager2018)
jeager2018 <- AddMetaData(jeager2018, jeager2018_meta)
#Make seurate object
jeager2018 <- CreateSeuratObject(counts = jeager2018_counts)
jeager2018_counts <- bind_cols(read.table('Jeager2018_GSE98679/GSE98679_count.txt.gz', header = TRUE, check.names = FALSE),
read.table('Jeager2018_GSE98679/GSE98679_v2_GSM3308862-GSM3309413_count.txt.gz', header = TRUE, check.names = FALSE))
jeager2018_meta <- read.csv('Jeager2018_GSE98679/SraRunTable.txt', header = TRUE)
jeager2018_meta = jeager2018_meta[c(1:46,599:912,47:598),] #we need to fix Jeager's files up a bit
rownames(jeager2018_meta) <- c(1:912)
jeager2018_counts <- bind_cols(read.table('Jeager2018_GSE98679/GSE98679_count.txt.gz', header = TRUE, check.names = FALSE),
read.table('Jeager2018_GSE98679/GSE98679_v2_GSM3308862-GSM3309413_count.txt.gz', header = TRUE, check.names = FALSE))
jeager2018_meta <- read.csv('Jeager2018_GSE98679/SraRunTable.txt', header = TRUE)
#
#
#
#
#
# first attempt at a classifier
setwd("C:/Users/angus/Desktop/PavLabEngrams/EngramCellClassifier")
jeager2018_counts <- bind_cols(read.table('Jeager2018_GSE98679/GSE98679_count.txt.gz', header = TRUE, check.names = FALSE),
read.table('Jeager2018_GSE98679/GSE98679_v2_GSM3308862-GSM3309413_count.txt.gz', header = TRUE, check.names = FALSE))
jeager2018_meta <- read.csv('Jeager2018_GSE98679/SraRunTable.txt', header = TRUE)
jeager2018_meta = jeager2018_meta[c(1:46,599:912,47:598),] #we need to fix Jeager's files up a bit
rownames(jeager2018_meta) <- c(1:912)
View(jeager2018_meta)
rownames(jeager2018_meta) <- colnames(jeager2018_counts)
jeager2018_meta$predicted_cell_type <- as.character(lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x}))
jeager2018_meta$predicted_cell_type <- lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x})
#Finding engram cells
fospos <- which(grepl("_F_DG",  jeager2018_meta$source_name))
fospos <- c(fospos,361:912) # since we know all the v2 cells from time points and recall testing
neg <- which(grepl("_N_DG",  jeager2018_meta$source_name))
View(jeager2018_meta)
jeager2018_meta$fos_status <- as.factor(sapply(as.character(jeager2018_meta$source_name[filtered.idx]), function(y) if (grepl("_F_", y, fixed=TRUE)) "Fos+" else "Fos-"  ))
jeager2018_meta$fos_status <- as.factor(sapply(as.character(jeager2018_meta$source_name), function(y) if (grepl("_F_", y, fixed=TRUE)) "Fos+" else "Fos-"  ))
dim(jeager2018_meta)
filtered.idx
under4k <- sapply(jeager2018_counts[,c(1:360)], function(y) sum(length(which(y>0))))
filtered.idx <- as.numeric(which(under4k>4000))
filtered.idx <- order(c(filtered.idx,194))
filtered.idx
under4k
#filtering out cells as per instructions in Jeager et al., 2018)
under4k <- sapply(jeager2018_counts, function(y) sum(length(which(y>0))))
dim(under4k)
length(under4k)
filtered.idx <- as.numeric(which(under4k>4000))
filtered.idx <- order(c(filtered.idx,194))
rownames(jeager2018_meta) <- c(1:912)
jeager2018_meta <- read.csv('Jeager2018_GSE98679/SraRunTable.txt', header = TRUE)
jeager2018_meta = jeager2018_meta[c(1:46,599:912,47:598),] #we need to fix Jeager's files up a bit
rownames(jeager2018_meta) <- c(1:912)
jeager2018_meta$predicted_cell_type <- as.character(lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x}))
jeager2018_meta$predicted_cell_type <- lapply(jeager2018_meta$predicted_cell_type, function(x) if (x=="") {"DG"} else {x})
#Finding engram cells
fospos <- which(grepl("_F_DG",  jeager2018_meta$source_name))
fospos <- c(fospos,361:912) # since we know all the v2 cells from time points and recall testing
neg <- which(grepl("_N_DG",  jeager2018_meta$source_name))
jeager2018_meta$fos_status <- as.factor(sapply(as.character(jeager2018_meta$source_name), function(y) if (grepl("_F_", y, fixed=TRUE)) "Fos+" else "Fos-"  ))
.character(jeager2018_meta$source_name), function(y) if (grepl("_F_", y, fixed=TRUE)) "Fos+" else "Fos-"  ))
#filtering out cells as per instructions in Jeager et al., 2018)
under4k <- sapply(jeager2018_counts, function(y) sum(length(which(y>0))))
filtered.idx <- as.numeric(which(under4k>4000))
filtered.idx <- order(c(filtered.idx,194))
jeager2018_counts <-jeager2018_counts[,filtered.idx]
jeager2018_meta <- jeager2018_meta[filtered.idx,]
log(1)
log(1+1)
#Make seurate object
jeager2018 <- CreateSeuratObject(counts = log(jeager2018_counts+1))
jeager2018 <- FindVariableFeatures(jeager2018, selection.method = "vst", nfeatures = 3530) #no idea how I chose 3530,
# in the tutorial they chose 2000, I just chose to match the number of cells we had
#jeager2018nobatch <- ScaleData(jeager2018)
rownames(jeager2018_meta) <- colnames(jeager2018_counts)
jeager2018 <- AddMetaData(jeager2018, jeager2018_meta)
#Make seurate object
jeager2018_counts[is.na(jeager2018_counts)] = 0
jeager2018 <- CreateSeuratObject(counts = log(jeager2018_counts+1))
jeager2018 <- FindVariableFeatures(jeager2018, selection.method = "vst", nfeatures = 3530) #no idea how I chose 3530,
rownames(jeager2018_meta) <- colnames(jeager2018_counts)
jeager2018 <- AddMetaData(jeager2018, jeager2018_meta)
View(jeager2018)
test_habib2016_counts <- read.csv("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz", header=TRUE)
test_habib2016_meta <- read.csv("test_datasets/Habib2016/SraRunTable", header =TRUE)
getwd()
test_habib2016_meta <- read.csv("test_datasets/Habib2016/SraRunTable.txt", header =TRUE)
View(test_habib2016_counts)
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz")
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz")
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz", header = TRUE)
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz", header = TRUE fill =TRUE)
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_series_matrix.txt.gz", header = TRUE, fill = TRUE)
View(test_habib2016_counts)
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_family.wml.tgz")
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_family.xml.tgz")
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_family.xml.tgz", header = TRUE)
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE84371_family.xml.tgz", header = TRUE, fill = TRUE)
install.packages("XML")
library(XML)
test_habib2016_counts <- xmltoDataFrame("test_datasets/Habib2016/GSE84371_family.xml.tgz")
test_habib2016_counts <- xmlToDataFrame("test_datasets/Habib2016/GSE84371_family.xml.tgz")
test_habib2016_counts <- read.table("test_datasets/Habib2016/GSE85721_PROCESSED_data.sNuc-Seq_Data_RSEM_log_TPM.for_GEO.txt.gz", header = TRUE)
View(test_habib2016_counts)
rm(test_habib2016_counts)
test_habib2016_logTPM <- read.table("test_datasets/Habib2016/GSE85721_PROCESSED_data.sNuc-Seq_Data_RSEM_log_TPM.for_GEO.txt.gz", header = TRUE)
test_habib2016_logTPM <- test_habib2016_logTPM[, 1]  ## set rownames
test_habib2016_logTPM <- test_habib2016_logTPM[, -1]
head(test_habib2016_logTPM[, 1])
test_habib2016_logTPM[, 1]
test_habib2016_logTPM <- read.table("test_datasets/Habib2016/GSE85721_PROCESSED_data.sNuc-Seq_Data_RSEM_log_TPM.for_GEO.txt.gz", header = TRUE)
rownames(test_habib2016_logTPM) <- test_habib2016_logTPM[, 1]  ## set rownames
View(test_habib2016_logTPM)
test_habib2016_logTPM <- test_habib2016_logTPM[, 2:925]
colnames(test_habib2016_logTPM)
sum(tr_detect(colnames(test_habib2016_logTPM), ".DG"))
sum(str_detect(colnames(test_habib2016_logTPM), ".DG"))
paste("t","i","ts", sep="")
habib2016.dg.idx <- which(str_detect(colnames(test_habib2016_logTPM), ".DG"))
habib2016.dg.idx
remotes::install_github("skimlab/CCSBUtils")
install.packages("GeoTcgaData")
library(GeoTcgaData)
install.packages("cqn")
BiocManager::install("cqn")
library(cqn)
library(GeoTcgaData)
#we must convert the jeager data to log tpm
# note that tpm may be  hihgly problematic for drawing conclusions from,
# we need to find the count data for this habib dataset
#
#Don't be discouraged if this does not work
data.list <- c(log(countToTpm_matrix(jeager2018_counts)),
test_habib2016_logTPM[,habib2016.dg.idx])
library(Seurat)
library(SeuratData)
library(patchwork)
InstallData("ifnb")
# load dataset
LoadData("ifnb")
# split the dataset into a list of two seurat objects (stim and CTRL)
ifnb.list <- SplitObject(ifnb, split.by = "stim")
# normalize and identify variable features for each dataset independently
ifnb.list <- lapply(X = ifnb.list, FUN = function(x) {
x <- NormalizeData(x)
x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})
View(ifnb.list)
rm(data.list)
data.list <- c(CreateSeuratObject(counts = log(countToTpm_matrix(jeager2018_counts)),
meta.data = jeager2018_meta),
CreateSeuratObject(counts = test_habib2016_logTPM[,habib2016.dg.idx],
meta.data = test_habib2016_meta[habib2016.dg.idx,])
)#end of data.list
colnames(test_habib2016_meta) <- rownames(test_habib2016_logTPM)
View(test_habib2016_meta)
rownames(test_habib2016_meta) <- colnames(test_habib2016_logTPM)
data.list <- c(CreateSeuratObject(counts = log(countToTpm_matrix(jeager2018_counts)),
meta.data = jeager2018_meta),
CreateSeuratObject(counts = test_habib2016_logTPM[,habib2016.dg.idx],
meta.data = test_habib2016_meta[habib2016.dg.idx,])
)#end of data.list
data.list <- FindVariableFeatures(data.list)
View(ifnb.list)
data.list <- CreateSeuratObject(data.list)
shared.genes <- rownames(test_habib2019_logTPM) %in% rownmaes(jeager2018_counts)
shared.genes <- rownames(test_habib2016_logTPM) %in% rownmaes(jeager2018_counts)
shared.genes <- rownames(test_habib2016_logTPM) %in% rownames(jeager2018_counts)
sum(shared.genes)
shared.genes <- c(rownames(test_habib2016_logTPM) %in% rownames(jeager2018_counts),
rownames(jeager2018_counts) %in% rownames(test_habib2016_logTPM))
shared.genes <- c(rownames(test_habib2016_logTPM) %in% rownames(jeager2018_counts),
rownames(jeager2018_counts) %in% rownames(test_habib2016_logTPM))
#Don't be discouraged if this does not work
data.list <- c(CreateSeuratObject(counts = log(countToTpm_matrix(jeager2018_counts[shared.genes[1]])),
meta.data = jeager2018_meta),
CreateSeuratObject(counts = test_habib2016_logTPM[shared.genes[2],habib2016.dg.idx],
meta.data = test_habib2016_meta[habib2016.dg.idx,])
)#end of data.list
View(dat)
View(data.list)
sum(shared.genes[2])
shared.genes[2]
rownames(jeager2018_counts) %in% rownames(test_habib2016_logTPM)
shared.genes <- c(rownames(test_habib2016_logTPM) %in% rownames(jeager2018_counts),
rownames(jeager2018_counts) %in% rownames(test_habib2016_logTPM))
shared.genes[2]
colnames(jeager2018_meta)
colnames(test_habib2016_meta)
